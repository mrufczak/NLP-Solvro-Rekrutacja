# Projekt AI/ML: Asystent Koktajli (RAG + MCP)

Projekt ten jest implementacjÄ… narzÄ™dzia typu **RAG (Retrieval-Augmented Generation)** udostÄ™pnianego przez serwer **MCP (Model Context Protocol)**. 

Celem jest stworzenie inteligentnego asystenta, ktÃ³ry potrafi odpowiadaÄ‡ na pytania dotyczÄ…ce koktajli oraz sugerowaÄ‡ drinki na podstawie podanych skÅ‚adnikÃ³w. CaÅ‚a wiedza asystenta jest ograniczona *wyÅ‚Ä…cznie* do dostarczonego pliku `thecocktailsdb.json`, co oznacza, Å¼e nie bÄ™dzie on odpowiadaÅ‚ na pytania spoza tej dziedziny.

---

## ğŸš€ GÅ‚Ã³wne Funkcje

* **Odpowiadanie na pytania:** MoÅ¼esz zapytaÄ‡ o przepis na dowolny koktajl z bazy (np. "Jak zrobiÄ‡ Mojito?").
* **Sugerowanie koktajli:** MoÅ¼esz zapytaÄ‡ o koktajle zawierajÄ…ce konkretne skÅ‚adniki (np. "Co mogÄ™ zrobiÄ‡ z ginu i soku z cytryny?").
* **Ograniczona wiedza:** System jest "zmuszony" do korzystania wyÅ‚Ä…cznie z dostarczonych danych RAG i nie bÄ™dzie odpowiadaÅ‚ na pytania ogÃ³lne (np. "Kto jest prezydentem Polski?").

---

## ğŸ› ï¸ UÅ¼yte Technologie

* **Python 3.10+**
* **Serwer API:** `FastMCP` (zgodnie z wymaganiami)
* **Silnik RAG:** `LangChain`
* **Baza Wektorowa:** `FAISS` (do szybkiego przeszukiwania semantycznego)
* **Embeddingi:** `HuggingFaceEmbeddings` (model `all-MiniLM-L6-v2`)
* **Lokalny LLM:** `LlamaCpp` (do Å‚adowania modeli GGUF bezpoÅ›rednio w Pythonie)
* **Klient:** `httpx` lub `LMStudio`(do komunikacji z serwerem z konsoli)

---

## âš™ï¸ Wymagania WstÄ™pne

Przed instalacjÄ… upewnij siÄ™, Å¼e masz na swoim systemie:
1.  **Python 3.10** lub nowszy oraz `pip`.
2.  Pobrany plik modelu LLM w formacie **GGUF**. Projekt byÅ‚ testowany z modelem `Meta-Llama-3-8B-Instruct-Q4_K_M.gguf`.
    * *MoÅ¼esz pobraÄ‡ ten model (lub mniejszy, np. Q2_K) za pomocÄ… aplikacji LM Studio.*
3.  Plik z danymi `thecocktailsdb.json` w gÅ‚Ã³wnym folderze projektu.

---

## 1. Instalacja

1.  Sklonuj repozytorium (lub pobierz pliki) i przejdÅº do folderu projektu.
2.  StwÃ³rz i aktywuj Å›rodowisko wirtualne:
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```
3.  Zainstaluj wszystkie wymagane biblioteki:
    ```bash
    pip install fastmcp langchain langchain_huggingface faiss-cpu llama-cpp-python httpx
    ```

---


## 2. Uruchomienie NarzÄ™dzia

NarzÄ™dzie skÅ‚ada siÄ™ z dwÃ³ch czÄ™Å›ci: serwera RAG i klienta konsolowego(lub LMStusio). Musisz je uruchomiÄ‡ w **dwÃ³ch osobnych terminalach**.

### Terminal 1: Uruchomienie Serwera RAG

W pierwszym terminalu (z aktywnym `.venv`) uruchom serwer `FastMCP`.

```bash
fastmcp run server.py:server --transport http --port 8000
```
W drugim terminalu (z aktywnym `.venv`) uruchom klienta

```bash
python client.py
```
---
KOD MOÅ»E ZAWIERAÄ† BÅÄ˜DY (nawet sporo :( )
Zadanie rozwiÄ…zywaÅ‚em z pomocÄ… gemini, gdyÅ¼ nie miaÅ‚em wystarczajÄ…co czasu na przeczytanie wystarczajÄ…cej dokumentacji i napisanie caÅ‚kowicie samemu kodu. Niemniej planuje nauczyÄ‡ siÄ™ w wolnym czasie wszystkiego, a zadanie chciaÅ‚em wykonaÄ‡ by mÃ³c przejÅ›Ä‡ do kolejnego etapu rekrutacji i nauczyÄ‡ siÄ™ wszystkiego po drodze. Jestem z kierunku SI na inÅ¼ynierce, wiÄ™c prÄ™dzej czy pÃ³Åºniej i tak bÄ™dÄ™ sie uczyÅ‚ podobnych rzeczy, a w tym momencie niestety brakuje mi czasu. Pozdrawiam :)
